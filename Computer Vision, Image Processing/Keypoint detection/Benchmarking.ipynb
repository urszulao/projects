{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"position":{"height":"591.85px","left":"878.583px","right":"20px","top":"120px","width":"800px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"kXdSCFNntOaV"},"source":["# **4.4 Detector & Descriptor Benchmarking**\n","\n","Now that we have met some of the most interesting keypoint detectors and descriptors, we are going to test them and compare their results in terms of **number of detections, robustness, invariance and performance**. \n","\n","In the context of our photo-stitching application, not all the keypoint detectors and descriptors seem to perform the same, right?\n","\n","Thus, in this notebook, you are asked to **evaluate** the following methods:\n","\n","- Harris + NCC\n","- Harris + ORB (descriptor)\n","- ORB \n","- SIFT\n","\n","in images that suffer **changes** in:\n","\n","- lighting conditions\n","- rotation\n","- scale\n","- point of view\n","\n","So, for each situation, you'll be provided with a pair of images that you will have to use to **detect, describe and match** the above-mentioned keypoints. \n","\n","After that, plot in a bar chart the following statistics:\n","\n","- average **number of keypoints** detected in the images,\n","- **number of matches** found,\n","- time spent **per keypoint** at detection (including description), and\n","- time spent **per match** during matching.\n","\n","> <font color=orange>Use `time.process_time()` from the [`time`](https://docs.python.org/3/library/time.html) package to measure time as follows.\n",">```\n",">t0 = time.process_time() # start timer\n","># process to be timed\n",">[...]\n",">t1 = round(time.process_time()-t0,5) # get elapsed time\n",">```\n","</font>"]},{"cell_type":"markdown","source":["**Preamble**"],"metadata":{"id":"G8vHBphb25Bm"}},{"cell_type":"code","metadata":{"id":"XU7r8f79tp87","executionInfo":{"status":"ok","timestamp":1685308046367,"user_tz":-120,"elapsed":19738,"user":{"displayName":"aa aa","userId":"07113411070203193765"}},"outputId":"750758ad-7eeb-451e-c4ac-16b53b700a79","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"5VBM4CVetOaW","executionInfo":{"status":"ok","timestamp":1685308046750,"user_tz":-120,"elapsed":388,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# preamble\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import time\n","matplotlib.rcParams['figure.figsize'] = (20.0, 20.0)\n","\n","images_path = '/gdrive/My Drive/Colab Notebooks/Chapter 4. Keypoint detection/images/'"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2rueOisLtOag"},"source":["## **4.4.0 Prepare output**\n","We first create a set of matrices to store the results, one for each scenario."]},{"cell_type":"code","metadata":{"id":"jwScSM1VtOak","executionInfo":{"status":"ok","timestamp":1685308046751,"user_tz":-120,"elapsed":6,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# Create output vectors\n","# We have 4 methods and 4 different scenarios\n","stats_kps  = np.zeros((4,4)) # for number of keypoints\n","stats_mat  = np.zeros((4,4)) # for number of matches\n","stats_tdet = np.zeros((4,4)) # for time per keypoint detected and described\n","stats_tmat = np.zeros((4,4)) # for time per match "],"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## **4.4.1 Preliminary functions**"],"metadata":{"id":"FYiV3WgXGbml"}},{"cell_type":"markdown","metadata":{"id":"0eiH3A4stOap"},"source":["### **<font color=\"green\">ASSIGNMENT #1a:  Harris and NCC (brought from 4.1 and adapted)</font>**\n","First, take the code you implemented in notebook 4.1 for the Harris method and transform it into **two functions** to:\n","- detect Harris keypoints (return a list of `cv2.Keypoint`). Use in here the `non-max-suppresion` method we provided to you.\n","- match Harris keypoints using NCC (return a list of `cv2.DMatch`)."]},{"cell_type":"code","source":["# Non-max-suppresion\n","# This method has been provided to you\n","from scipy import signal\n","def nonmaxsuppts(cim, radius, thresh):\n","    \"\"\" Binarize and apply non-maximum suppresion.   \n","    \n","        Args:\n","            cim: the harris 'R' image\n","            radius: the aperture size of local maxima window\n","            thresh: the threshold value for binarization\n","                    \n","        Returns: \n","            r, c: two numpy vectors being the row (r) and the column (c) of each keypoint\n","    \"\"\"   \n","    \n","    rows, cols = np.shape(cim)\n","    size = 2 * radius + 1\n","    mx = signal.order_filter(cim, np.ones([size, size]), size ** 2 - 1)\n","    bordermask = np.zeros([rows, cols]);\n","    bordermask[radius:(rows - radius), radius:(cols - radius)] = 1\n","    cim = np.array(cim)\n","    r, c = np.where((cim == mx) & (cim > thresh) & (bordermask == 1)) # row and cols\n","    kps = [cv2.KeyPoint(np.float32(c[i]), np.float32(r[i]), 2) for i in range(len(r))]        # keypoint list\n","\n","    return kps"],"metadata":{"id":"uT9Wy_zZ5Vvn","executionInfo":{"status":"ok","timestamp":1685308047973,"user_tz":-120,"elapsed":1228,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdY-f2iHtOar","executionInfo":{"status":"ok","timestamp":1685308047974,"user_tz":-120,"elapsed":6,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# Define a function to detect Harris\n","def detectHarris(image,w_size,sobel_size,k):\n","    \"\"\" Detects Harris keypoints and applies non-max-suppresion\n","    \n","        Args:\n","            image       : [numpy array] grayscale image\n","            w_size      : [integer] neighborhood (window) size\n","            sobel_size  : [integer] size of the Sobel kernel (must be an odd value)\n","            k           : [float] Harris response parameter [0.04,0.06]\n","           \n","        Returns:\n","            kps         : [list] list of cv2.KeyPoint\n","    \"\"\"\n","\n","    # Write your code here!\n","   \n","    return kps\n","    \n","# ... and another one to match them\n","def matchHarris(image_l,image_r,kps_l,kps_r):\n","    \"\"\" Adds 'borders' to the image and (robustly) matches Harris keypoints\n","    \n","        Args:\n","            image_l     : [numpy array] left grayscale image\n","            image_r     : [numpy array] right grayscale image\n","            kps_l       : [list] list of keypoints for left image\n","            kps_r       : [list] list of keypoints for right image\n","           \n","        Returns:\n","            matches     : [list] list of cv2.DMatch\n","    \"\"\"  \n","    # Write your code here!\n","        \n","    return matches"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tp0qN0kKtOaw"},"source":["### **<font color=\"green\">ASSIGNMENT #1b:  Create a process function for each method</font>** \n","\n","Now, **create a method** for each of the proposed algorithms:\n","- Harris + NCC\n","- Harris + ORB descriptor\n","- ORB\n","- SIFT\n","\n","that performs all the desired tasks for a pair of input images (insert both the grayscale and the color version of them). These functions should do the following:\n","- compute keypoints and descriptors from the grayscale image (also store the number of detected keypoint and measure the time spent in the process)\n","- find matches (also store the number of matches found and measure the time spent in the process)\n","- plot the resulting matches on the color images.\n","- return the **average number of keypoints per image**, the **number of matches**, the **detection time** and the **matching time**.\n","\n","**Once you have this, you just need to call them for each pair of images!**"]},{"cell_type":"code","metadata":{"id":"xsqnh1rJtOaw","executionInfo":{"status":"ok","timestamp":1685308047974,"user_tz":-120,"elapsed":5,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["def process_Harris_NCC(image_l, image_l_gray, image_r, image_r_gray):\n","    \"\"\" Finds Harris features and matches them using NCC. Also display the matches.\n","    \n","        Args:\n","            image_l     : [numpy array] left color image\n","            image_l_gray: [numpy array] left grayscale image\n","            image_r     : [numpy array] right grayscale image\n","            image_r_gray: [numpy array] right grayscale image\n","           \n","        Returns:\n","            num_kps     : [float] average number of keypoints per image\n","            num_matches : [integer] number of robust matches found\n","            tdet        : [float] time spent per keypoint detection and description\n","            tmat        : [float] time spent per match\n","    \"\"\"  \n","    # Write your code here!\n","    \n","    return num_kps, num_matches, tdet, tmat"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"mVJ796srtOa2","executionInfo":{"status":"ok","timestamp":1685308047976,"user_tz":-120,"elapsed":7,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["def process_Harris_ORB(image_l, image_l_gray, image_r, image_r_gray):\n","    \"\"\" Finds Harris features and matches them using the ORB descriptor. Also display the matches.\n","    \n","        Args:\n","            image_l     : [numpy array] left color image\n","            image_l_gray: [numpy array] left grayscale image\n","            image_r     : [numpy array] right grayscale image\n","            image_r_gray: [numpy array] right grayscale image\n","           \n","        Returns:\n","            num_kps     : [float] average number of keypoints per image\n","            num_matches : [integer] number of robust matches found\n","            tdet        : [float] time spent per keypoint detection and description\n","            tmat        : [float] time spent per match\n","    \"\"\"    \n","    # Write your code here!\n","    \n","    return num_kps, num_matches, tdet, tmat"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"LfnVcjd6tOa7","executionInfo":{"status":"ok","timestamp":1685308048252,"user_tz":-120,"elapsed":281,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["def process_ORB(image_l, image_l_gray, image_r, image_r_gray):\n","    \"\"\" Finds and matches ORB features. Also display the matches.\n","    \n","        Args:\n","            image_l     : [numpy array] left color image\n","            image_l_gray: [numpy array] left grayscale image\n","            image_r     : [numpy array] right grayscale image\n","            image_r_gray: [numpy array] right grayscale image\n","           \n","        Returns:\n","            num_kps     : [float] average number of keypoints per image\n","            num_matches : [integer] number of robust matches found\n","            tdet        : [float] time spent per keypoint detection and description\n","            tmat        : [float] time spent per match\n","    \"\"\"       \n","    # Write your code here!\n","    \n","    return num_kps, num_matches, tdet, tmat"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"wEmax5yftObA","executionInfo":{"status":"ok","timestamp":1685308048252,"user_tz":-120,"elapsed":4,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["def process_SIFT(image_l, image_l_gray, image_r, image_r_gray):\n","    \"\"\" Finds and matches SIFT features. Also display the matches.\n","    \n","        Args:\n","            image_l     : [numpy array] left color image\n","            image_l_gray: [numpy array] left grayscale image\n","            image_r     : [numpy array] right grayscale image\n","            image_r_gray: [numpy array] right grayscale image\n","           \n","        Returns:\n","            num_kps     : [float] average number of keypoints per image\n","            num_matches : [integer] number of robust matches found\n","            tdet        : [float] time spent per keypoint detection and description\n","            tmat        : [float] time spent per match\n","    \"\"\"           \n","    # Write your code here!\n","    \n","    return num_kps, num_matches, tdet, tmat"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## **4.4.2 Testing the methods!**"],"metadata":{"id":"NBvO2LGuGWHe"}},{"cell_type":"markdown","metadata":{"id":"vDe161rBtObH"},"source":["### **<font color=\"green\">ASSIGNMENT #2a: Changes in lighting conditions</font>** \n","\n","Use `bright1.png` and `bright2.png` images, which contain the same scene but with different lighting conditions.\n","<center>\n","<img src=\"https://raw.githubusercontent.com/famoreno/cv_jn_images/master/ch4/insert/bright1.png\" width=\"300\" align=\"left\"/><img src=\"https://raw.githubusercontent.com/famoreno/cv_jn_images/master/ch4/insert/bright2.png\" width=\"300\" align=\"rigth\"/>\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"pePjN3UstObJ"},"source":["#### **Read the images**\n","Read the images and convert them to gray (they will be used for all the methods)"]},{"cell_type":"code","metadata":{"id":"QSZtOKmHtObJ","executionInfo":{"status":"ok","timestamp":1685308049448,"user_tz":-120,"elapsed":1199,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# Read images and convert to gray\n","image_l = cv2.imread(images_path + 'bright1.png')\n","image_r = cv2.imread(images_path + 'bright2.png')\n","image_l = cv2.cvtColor(image_l,cv2.COLOR_BGR2RGB)\n","image_r = cv2.cvtColor(image_r,cv2.COLOR_BGR2RGB)\n","image_l_gray = cv2.cvtColor(image_l,cv2.COLOR_RGB2GRAY)\n","image_r_gray = cv2.cvtColor(image_r,cv2.COLOR_RGB2GRAY)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f85aj-OetObN"},"source":["#### **Make the tests**"]},{"cell_type":"code","metadata":{"id":"_7_oByzdtObO","executionInfo":{"status":"error","timestamp":1685308049871,"user_tz":-120,"elapsed":427,"user":{"displayName":"aa aa","userId":"07113411070203193765"}},"outputId":"5717dc0a-8b3e-4f3c-99e9-8150ae9aff4d","colab":{"base_uri":"https://localhost:8080/","height":304}},"source":["# HARRIS + NCC\n","stats_kps[0,0],stats_mat[0,0],stats_tdet[0,0],stats_tmat[0,0] = process_Harris_NCC(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-672f3264e517>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# HARRIS + NCC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstats_kps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats_tdet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats_tmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_Harris_NCC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_l_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_r_gray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-1e6c1fc7f246>\u001b[0m in \u001b[0;36mprocess_Harris_NCC\u001b[0;34m(image_l, image_l_gray, image_r, image_r_gray)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Write your code here!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnum_kps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_matches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'num_kps' is not defined"]}]},{"cell_type":"code","metadata":{"id":"w0oBf0iitObU","executionInfo":{"status":"aborted","timestamp":1685308049872,"user_tz":-120,"elapsed":25,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# HARRIS + ORB\n","stats_kps[0,1],stats_mat[0,1],stats_tdet[0,1],stats_tmat[0,1] = process_Harris_ORB(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9h4qAhBvtObZ","executionInfo":{"status":"aborted","timestamp":1685308049872,"user_tz":-120,"elapsed":25,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# ORB\n","stats_kps[0,2],stats_mat[0,2],stats_tdet[0,2],stats_tmat[0,2] = process_ORB(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ckBEyXkBtObc","executionInfo":{"status":"aborted","timestamp":1685308049872,"user_tz":-120,"elapsed":25,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# SIFT\n","stats_kps[0,3],stats_mat[0,3],stats_tdet[0,3],stats_tmat[0,3] = process_SIFT(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LlUTMOMBtObm"},"source":["### **<font color=\"green\">ASSIGNMENT #2b: Changes in rotation</font>** \n","\n","Use `rotate1.png` and `rotate2.png` images.\n","\n","<center>\n","<img src=\"https://raw.githubusercontent.com/famoreno/cv_jn_images/master/ch4/insert/rotate1.png\" width=\"300\" align=\"left\"/><img src=\"https://raw.githubusercontent.com/famoreno/cv_jn_images/master/ch4/insert/rotate2.png\" width=\"300\" align=\"rigth\"/>\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"TzNqDMZRtObm"},"source":["#### **Read the images**\n","Read the images and convert them to gray (they will be used for all the methods)"]},{"cell_type":"code","metadata":{"id":"-SeiR3srtObm","executionInfo":{"status":"aborted","timestamp":1685308049873,"user_tz":-120,"elapsed":24,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# Read images and convert to gray\n","image_l = cv2.imread(images_path + 'rotate1.png')\n","image_r = cv2.imread(images_path + 'rotate2.png')\n","image_l = cv2.cvtColor(image_l,cv2.COLOR_BGR2RGB)\n","image_r = cv2.cvtColor(image_r,cv2.COLOR_BGR2RGB)\n","image_l_gray = cv2.cvtColor(image_l,cv2.COLOR_RGB2GRAY)\n","image_r_gray = cv2.cvtColor(image_r,cv2.COLOR_RGB2GRAY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yr2qAmxztObq"},"source":["#### **Make the tests**"]},{"cell_type":"code","metadata":{"id":"pueliSJJtObr","executionInfo":{"status":"aborted","timestamp":1685308049873,"user_tz":-120,"elapsed":24,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# HARRIS + NCC\n","stats_kps[1,0],stats_mat[1,0],stats_tdet[1,0],stats_tmat[1,0] = process_Harris_NCC(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySx7nZE4tObu","executionInfo":{"status":"aborted","timestamp":1685308049873,"user_tz":-120,"elapsed":24,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# HARRIS + ORB\n","stats_kps[1,1],stats_mat[1,1],stats_tdet[1,1],stats_tmat[1,1] = process_Harris_ORB(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4EVrEOY_tOby","executionInfo":{"status":"aborted","timestamp":1685308049874,"user_tz":-120,"elapsed":24,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# ORB\n","stats_kps[1,2],stats_mat[1,2],stats_tdet[1,2],stats_tmat[1,2] = process_ORB(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kb28Ob7JtOb0","executionInfo":{"status":"aborted","timestamp":1685308049874,"user_tz":-120,"elapsed":24,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# SIFT\n","stats_kps[1,3],stats_mat[1,3],stats_tdet[1,3],stats_tmat[1,3] = process_SIFT(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLLaYtaXtOb8"},"source":["### **<font color=\"green\">ASSIGNMENT #2c: Changes in scale</font>** \n","\n","Use `scale1.png` and `scale2.png` images.\n","\n","<center>\n","<img src=\"https://raw.githubusercontent.com/famoreno/cv_jn_images/master/ch4/insert/scale1.png\" width=\"300\" align=\"left\"/><img src=\"https://raw.githubusercontent.com/famoreno/cv_jn_images/master/ch4/insert/scale2.png\" width=\"300\" align=\"rigth\"/>\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"2FzJLl_WtOb9"},"source":["#### **Read the images**\n","Read the images and convert them to gray (they will be used for all the methods)"]},{"cell_type":"code","metadata":{"id":"CYwaY_k7tOb9","executionInfo":{"status":"aborted","timestamp":1685308049875,"user_tz":-120,"elapsed":25,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# Read images and convert to gray\n","image_l = cv2.imread(images_path + 'scale1.png')\n","image_r = cv2.imread(images_path + 'scale2.png')\n","image_l = cv2.cvtColor(image_l,cv2.COLOR_BGR2RGB)\n","image_r = cv2.cvtColor(image_r,cv2.COLOR_BGR2RGB)\n","image_l_gray = cv2.cvtColor(image_l,cv2.COLOR_RGB2GRAY)\n","image_r_gray = cv2.cvtColor(image_r,cv2.COLOR_RGB2GRAY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6k5ejEWCtOcC"},"source":["#### **Make the tests**"]},{"cell_type":"code","metadata":{"id":"kEFtWMn8tOcD","executionInfo":{"status":"aborted","timestamp":1685308049875,"user_tz":-120,"elapsed":23,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# HARRIS + NCC\n","stats_kps[2,0],stats_mat[2,0],stats_tdet[2,0],stats_tmat[2,0] = process_Harris_NCC(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SI2YfBqhtOcH","executionInfo":{"status":"aborted","timestamp":1685308049875,"user_tz":-120,"elapsed":23,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# HARRIS + ORB\n","stats_kps[2,1],stats_mat[2,1],stats_tdet[2,1],stats_tmat[2,1] = process_Harris_ORB(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKHAfjsAtOcK","executionInfo":{"status":"aborted","timestamp":1685308049875,"user_tz":-120,"elapsed":22,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# ORB\n","stats_kps[2,2],stats_mat[2,2],stats_tdet[2,2],stats_tmat[2,2] = process_ORB(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISTZCenJtOcO","executionInfo":{"status":"aborted","timestamp":1685308049876,"user_tz":-120,"elapsed":22,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# SIFT\n","stats_kps[2,3],stats_mat[2,3],stats_tdet[2,3],stats_tmat[2,3] = process_SIFT(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OW1y76-jtOcT"},"source":["### **<font color=\"green\">ASSIGNMENT #2d: Changes in point of view</font>** \n","\n","Use `pov1.png` and `pov2.png` images.\n","<center>\n","<img src=\"https://raw.githubusercontent.com/famoreno/cv_jn_images/master/ch4/insert/pov1.png\" width=\"300\" align=\"left\"/><img src=\"https://raw.githubusercontent.com/famoreno/cv_jn_images/master/ch4/insert/pov2.png\" width=\"300\" align=\"rigth\"/>\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"dlhXzmTKtOcU"},"source":["#### **Read the images**\n","Read the images and convert them to gray (they will be used for all the methods)"]},{"cell_type":"code","metadata":{"id":"lomBjt7AtOcU","executionInfo":{"status":"aborted","timestamp":1685308049876,"user_tz":-120,"elapsed":22,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# Read images and convert to gray\n","image_l = cv2.imread(images_path + 'pov1.png')\n","image_r = cv2.imread(images_path + 'pov2.png')\n","image_l = cv2.cvtColor(image_l,cv2.COLOR_BGR2RGB)\n","image_r = cv2.cvtColor(image_r,cv2.COLOR_BGR2RGB)\n","image_l_gray = cv2.cvtColor(image_l,cv2.COLOR_RGB2GRAY)\n","image_r_gray = cv2.cvtColor(image_r,cv2.COLOR_RGB2GRAY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nxgsa2k1tOcW"},"source":["#### **Make the tests**"]},{"cell_type":"code","metadata":{"id":"-2TnyZijtOcY","executionInfo":{"status":"aborted","timestamp":1685308049876,"user_tz":-120,"elapsed":21,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# HARRIS + NCC\n","stats_kps[3,0],stats_mat[3,0],stats_tdet[3,0],stats_tmat[3,0] = process_Harris_NCC(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ZUOyTkotOcb","executionInfo":{"status":"aborted","timestamp":1685308049876,"user_tz":-120,"elapsed":21,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# HARRIS + ORB\n","stats_kps[3,1],stats_mat[3,1],stats_tdet[3,1],stats_tmat[3,1] = process_Harris_ORB(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbKnYRkjtOcd","executionInfo":{"status":"aborted","timestamp":1685308049877,"user_tz":-120,"elapsed":21,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# ORB\n","stats_kps[3,2],stats_mat[3,2],stats_tdet[3,2],stats_tmat[3,2] = process_ORB(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuDDipMRtOcg","executionInfo":{"status":"aborted","timestamp":1685308049877,"user_tz":-120,"elapsed":21,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# SIFT\n","stats_kps[3,3],stats_mat[3,3],stats_tdet[3,3],stats_tmat[3,3] = process_SIFT(image_l, image_l_gray, image_r, image_r_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **4.4.3 Graphically analyzing the results**\n","Finally, we are going to plot graphically the results stored in the previous steps."],"metadata":{"id":"tn_3S8wuGn8U"}},{"cell_type":"markdown","metadata":{"id":"BqYA2B_YtOco"},"source":["### **<font color=\"green\">ASSIGNMENT #3: Plot the results</font>** \n","\n","Now generate four plots with the following metrics:\n","- average number of keypoints detected in the images\n","- number of found matches\n","- time spent per keypoint at detection (including description)\n","- time spent per match during matching\n","\n","Create a 4x4 plot with [bar](https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.bar.html) graphs with a **row for each metric** (*#keypoints*, *#matches*, *detection time*, and *matching time*) and a **column for each test** (*lighting conditions*, *rotation*, *scale* and *point-of-view*)."]},{"cell_type":"code","metadata":{"id":"zCaRdktjtOco","executionInfo":{"status":"aborted","timestamp":1685308049877,"user_tz":-120,"elapsed":19,"user":{"displayName":"aa aa","userId":"07113411070203193765"}}},"source":["# Generate graphs\n","matplotlib.rcParams['figure.figsize'] = (18.0, 18.0)\n","\n","titles = ('Lighting', 'Rotation', 'Scale', 'Point-of-view')\n","objects = ('H+NCC', 'H+ORB', 'ORB', 'SIFT')\n","y_pos = np.arange(len(objects))\n","\n","# keypoints\n","for i in range(1,5):\n","    plt.subplot(4,4,i)\n","    plt.bar(y_pos, stats_kps[i-1,:], align='center', alpha=0.5)\n","    plt.xticks(y_pos, objects)\n","    plt.ylabel('# kps')\n","    plt.title(titles[i-1])\n","\n","# matches\n","for i in range(1,5):\n","    plt.subplot(4,4,i+4)\n","    plt.bar(y_pos, stats_mat[i-1,:], align='center', alpha=0.5)\n","    plt.xticks(y_pos, objects)\n","    plt.ylabel('# matches')\n","    plt.title(titles[i-1])\n","\n","# time per detection\n","for i in range(1,5):\n","    ax = plt.subplot(4,4,i+8)\n","    ax.set_yscale('log')\n","    plt.bar(y_pos, stats_tdet[i-1,:], align='center', alpha=0.5)\n","    plt.xticks(y_pos, objects)\n","    plt.ylabel('t_det [s]')\n","    plt.title(titles[i-1])\n","\n","# time per match\n","for i in range(1,5):\n","    ax = plt.subplot(4,4,i+12)\n","    ax.set_yscale('log')\n","    plt.bar(y_pos, stats_tmat[i-1,:], align='center', alpha=0.5)\n","    plt.xticks(y_pos, objects)\n","    plt.ylabel('t_mat [s]')\n","    plt.title(titles[i-1])\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1zFBooTNtOcq"},"source":["#### <font color=\"blue\"><b>Discussion #1</b></font>\n","\n","Now that you have finished these tests, answer the following questions:\n","\n","- Are the evaluated methods invariant to these changes?\n","  \n","    <font color=blue><b>Your answer here!</b></font>\n","    \n","- Which one would you use to work with each kind of images?\n","    \n","    <font color=blue><b>Your answer here!</b></font>\n","  \n","- Which one would you use if you need a real-time system?\n","\n","    <font color=blue><b>Your answer here!</b></font>\n","  \n","- If there is any method NOT invariant against a certain change, can you think in any solution to make it more robust against that?\n","\n","    <font color=blue><b>Your answer here!</b></font>"]}]}